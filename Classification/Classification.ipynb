{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edaf0ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from random import seed, randint\n",
    "import json\n",
    "from scipy.io import loadmat, savemat\n",
    "from scipy.spatial.distance import euclidean, mahalanobis\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, roc_curve\n",
    "from sklearn.neighbors import NearestCentroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5907f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcl = {'EO': loadmat('MCL.mat')['EO'].reshape(109, 6, 64, 1), 'EC': loadmat('MCL.mat')['EC'].reshape(109, 6, 64, 1)}\n",
    "kfd = {'EO': loadmat('KFD.mat')['EO'].reshape(109, 6, 64, 1), 'EC': loadmat('KFD.mat')['EC'].reshape(109, 6, 64, 1)}\n",
    "hm = {'EO': loadmat('HM.mat')['EO'].reshape(109, 6, 64, 1), 'EC': loadmat('HM.mat')['EC'].reshape(109, 6, 64,1)}\n",
    "psd = {'EO': loadmat('PSD.mat')['EO'], 'EC': loadmat('PSD.mat')['EC']}\n",
    "ap = {'EO': loadmat('AP.mat')['EO'], 'EC': loadmat('AP.mat')['EC']}\n",
    "plv = {'EO': loadmat('PLV.mat')['EO'], 'EC': loadmat('PLV.mat')['EC']}\n",
    "coh = {'EO': loadmat('COH.mat')['EO'], 'EC': loadmat('COH.mat')['EC']}\n",
    "ar = {'EO': loadmat('AR.mat')['EO'], 'EC': loadmat('AR.mat')['EC']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9713c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Euclidean(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.y = np.array(list(set(y)))\n",
    "        self.X = np.zeros((len(self.y), X.shape[1]))\n",
    "        for i in range(len(self.y)):\n",
    "            self.X[i] = X[y==self.y[i]].mean(axis=0)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        p = np.ones(X.shape[0], dtype='int32')*self.y[0]\n",
    "        for i, x in enumerate(X):\n",
    "            s = euclidean(x, self.X[0])\n",
    "            for j in range(1, len(self.y)):\n",
    "                d = euclidean(x, self.X[j])\n",
    "                if d < s:\n",
    "                    s = d\n",
    "                    p[i] = self.y[j]\n",
    "        return p\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        p = np.zeros((X.shape[0], self.X.shape[0]))\n",
    "        for i, x in enumerate(X):\n",
    "            for j in range(len(self.y)):\n",
    "                p[i, j] = euclidean(x, self.X[j])\n",
    "        return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f1e207",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mahalanobis(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, VI=None):\n",
    "        self.VI = VI\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.y = np.array(list(set(y)))\n",
    "        self.X = np.zeros((len(self.y), X.shape[1]))\n",
    "        for i in range(len(self.y)):\n",
    "            self.X[i] = X[y==self.y[i]].mean(axis=0)\n",
    "        if self.VI is None:\n",
    "            self.VI = np.linalg.inv(np.cov(X.transpose()))\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        p = np.ones(X.shape[0], dtype='int32')*self.y[0]\n",
    "        for i, x in enumerate(X):\n",
    "            s = mahalanobis(x, self.X[0], self.VI)\n",
    "            for j in range(1, len(self.y)):\n",
    "                d = mahalanobis(x, self.X[j], self.VI)\n",
    "                if d < s:\n",
    "                    s = d\n",
    "                    p[i] = self.y[j]\n",
    "        return p\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        p = np.zeros((X.shape[0], self.X.shape[0]))\n",
    "        for i, x in enumerate(X):\n",
    "            for j in range(len(self.y)):\n",
    "                p[i, j] = mahalanobis(x, self.X[j], self.VI)\n",
    "        return p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70409e8",
   "metadata": {},
   "source": [
    "# Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962f1ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table I & II\n",
    "\n",
    "features = {'MCL': mcl, 'KFD': kfd, 'HM': hm, 'PSD': psd, 'AP': ap, 'PLV': plv, 'COH': coh, 'AR': ar}\n",
    "protocols = ['EO', 'EC']\n",
    "accuracy_scores = {'MCL': {'EO': None, 'EC': None}, 'KFD': {'EO': None, 'EC': None},\n",
    "                   'HM':  {'EO': None, 'EC': None}, 'PSD': {'EO': None, 'EC': None},\n",
    "                   'AP':  {'EO': None, 'EC': None}, 'PLV': {'EO': None, 'EC': None},\n",
    "                   'COH': {'EO': None, 'EC': None}, 'AR':  {'EO': None, 'EC': None}}\n",
    "n_components = accuracy_scores.copy()\n",
    "y_train = np.array([i for i in range(109) for j in range(5)])\n",
    "y_test = np.array([i for i in range(109)])\n",
    "\n",
    "for feature in features.keys():\n",
    "    if feature in {'PLV', 'COH', 'AR'}:\n",
    "        n_comp = 0.99\n",
    "    else:\n",
    "        n_comp = None\n",
    "    for protocol in protocols:\n",
    "        accuracy_scores_ = [0]*6\n",
    "        n_components_ = [0]*6\n",
    "        for i in range(6):\n",
    "            \n",
    "            train_set = list(range(6))\n",
    "            test_set = [train_set.pop(i)]\n",
    "            \n",
    "            x_train = features[feature][protocol][:, train_set, :, :].reshape(109*5, -1)\n",
    "            x_test = features[feature][protocol][:, test_set, :, :].reshape(109*1, -1)\n",
    "            \n",
    "            pca = PCA(n_components=n_comp, whiten=True)\n",
    "            clf = NearestCentroid('euclidean')\n",
    "            model = Pipeline([('pca', pca), ('clf', clf)])\n",
    "            model.fit(x_train, y_train)\n",
    "            \n",
    "            accuracy_scores_[i] = accuracy_score(y_test, model.predict(x_test))*100\n",
    "            n_components_[i] = model.named_steps['pca'].n_components_\n",
    "        \n",
    "        accuracy_scores[feature][protocol] = accuracy_scores_\n",
    "        n_components[feature][protocol] = n_components_\n",
    "        print(feature+'-'+protocol+':',\n",
    "              np.mean(accuracy_scores_).round(1), '\\N{PLUS-MINUS SIGN}', np.std(accuracy_scores_).round(1), '%',\n",
    "              '\\t', int(np.mean(n_components_).round()), 'p.c.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3aa783b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table I\n",
    "\n",
    "print('Average Number of Components\\n')\n",
    "for feature in {'PLV', 'COH', 'AR'}:\n",
    "    print(feature+':', int(np.mean([n_components[feature]['EO'], n_components[feature]['EC']]).round()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab2e058",
   "metadata": {},
   "source": [
    "# Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b04e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array([i==j for i in range(109) for j in range(109)]*6)\n",
    "def cross_validate(data, N, n_comp=None):\n",
    "    y_train = np.array([i for i in range(N) for j in range(5)])\n",
    "    y_score = []\n",
    "    \n",
    "    for i in range(6):\n",
    "        \n",
    "        train_set = list(range(6))\n",
    "        test_set = [train_set.pop(i)]\n",
    "        \n",
    "        x_train = data[:N, train_set, :, :].reshape([N*5, -1])\n",
    "        x_test = data[:N, test_set, :, :].reshape([N*1, -1])\n",
    "        if N < 109:\n",
    "            x_imposter = data[N:, :, :, :].reshape([(109-N)*6, -1])\n",
    "        \n",
    "        pca = PCA(n_components=n_comp, whiten=True)\n",
    "        clf = Euclidean()\n",
    "        model = Pipeline([('pca', pca), ('clf', clf)])\n",
    "        model.fit(x_train, y_train)\n",
    "        \n",
    "        y_score.extend(model.predict_proba(x_test).ravel())\n",
    "    \n",
    "    return np.array(y_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210b5aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "protocols = ['EO', 'EC']\n",
    "features = {'MCL': mcl, 'KFD': kfd, 'HM': hm, 'PSD': psd, 'AP': ap, 'PLV': plv, 'COH': coh, 'AR': ar}\n",
    "y_score = dict()\n",
    "for feature in features.keys():\n",
    "    y_score[feature] = {'EO': None, 'EC': None}\n",
    "\n",
    "for feature in features.keys():\n",
    "    if feature in ['PLV', 'COH', 'AR']:\n",
    "        n_comp = 0.99\n",
    "    else:\n",
    "        n_comp = None\n",
    "    for protocol in protocols:\n",
    "        y_score[feature][protocol] = cross_validate(features[feature][protocol], 109, n_comp)\n",
    "    print(feature+' done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421fc323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# since distance is a dissimilarity-based measure negatives are positives and vice versa\n",
    "fpr = dict()\n",
    "fnr = dict()\n",
    "eer = dict()\n",
    "for feature in features.keys():\n",
    "    fpr[feature] = {'EO': None, 'EC': None}\n",
    "    fnr[feature] = {'EO': None, 'EC': None}\n",
    "    eer[feature] = {'EO': None, 'EC': None}\n",
    "\n",
    "for feature in features.keys():\n",
    "    for protocol in protocols:\n",
    "        fpr_tmp, tpr_tmp, _ = roc_curve(y_true, -y_score[feature][protocol])\n",
    "        fnr_tmp = 1-tpr_tmp\n",
    "        fpr[feature][protocol] = fpr_tmp\n",
    "        fnr[feature][protocol] = fnr_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a234353b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fig. 4\n",
    "\n",
    "protocol_titles = ['Eyes Open', 'Eyes Close']\n",
    "line_format = {'MCL': {'EO': 'b', 'EC': 'b'},           'KFD': {'EO': 'r', 'EC': 'r'},\n",
    "               'HM':  {'EO': 'orange', 'EC': 'orange'}, 'PSD': {'EO': 'g', 'EC': 'g'},\n",
    "               'AP':  {'EO': 'y', 'EC': 'y'},           'PLV': {'EO': 'c', 'EC': 'c'},\n",
    "               'COH': {'EO': 'm', 'EC': 'm'},            'AR': {'EO': 'k', 'EC': 'k'}}\n",
    "\n",
    "for i, protocol in enumerate(protocols):\n",
    "    \n",
    "    legend = []\n",
    "    \n",
    "    plt.subplot(1, 2, i+1)\n",
    "    for feature in features.keys():\n",
    "        if feature != 'MCL':\n",
    "            lw = 0.75\n",
    "        else:\n",
    "            lw = 3\n",
    "        plt.plot(fpr[feature][protocol], fnr[feature][protocol], line_format[feature][protocol], linewidth=lw)\n",
    "        legend.append(feature)\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=1)\n",
    "    plt.text(0.30, 0.37, 'EER Line', fontsize=12, weight='semibold', color='black')\n",
    "    \n",
    "    plt.xticks(fontsize=12), plt.yticks(fontsize=12)\n",
    "    plt.xlabel('False Acceptance Rate', fontsize=16), plt.ylabel('False Rejection Rate', fontsize=16)\n",
    "    plt.title(protocol_titles[i], weight='normal', fontsize=18)\n",
    "    plt.legend(legend, fontsize=12, loc='right')\n",
    "    \n",
    "    plt.grid(ls=':')\n",
    "    plt.axis('square')\n",
    "    plt.xlim([0, 0.4]), plt.ylim([0, 0.4])\n",
    "    \n",
    "plt.gcf().set_size_inches(15, 15)\n",
    "\n",
    "for feature in features.keys():\n",
    "    for protocol in protocols:\n",
    "        eer_idx = np.argmin(np.abs(fpr[feature][protocol]-fnr[feature][protocol]))\n",
    "        eer[feature][protocol] = np.mean([fpr[feature][protocol][eer_idx], fnr[feature][protocol][eer_idx]]).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7123d5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table II\n",
    "\n",
    "eer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5165121",
   "metadata": {},
   "source": [
    "# Channel Ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1ae22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(model, chan_set, protocol):\n",
    "    protocol = 'EO'\n",
    "    acc = 0\n",
    "    for i in range(6):\n",
    "        train_set = list(range(6))\n",
    "        test_set = [train_set.pop(i)]\n",
    "        x_train = mcl[protocol][:, train_set, :][:, :, chan_set].reshape(109*5, -1)\n",
    "        x_test = mcl[protocol][:, test_set, :][:, :, chan_set].reshape(109*1, -1)\n",
    "        model.fit(x_train, y_train)\n",
    "        acc += accuracy_score(y_test, model.predict(x_test))/6*100\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8617617d",
   "metadata": {},
   "outputs": [],
   "source": [
    "protocols = ['EO', 'EC']\n",
    "ranked_chans = {'EO': [0]*64, 'EC': [0]*64}\n",
    "\n",
    "for protocol in protocols:\n",
    "    accuracy_scores = [0]*64\n",
    "    y_train = np.array([i for i in range(109) for j in range(5)])\n",
    "    y_test = np.array([i for i in range(109)])\n",
    "    remaining_chans = list(range(64))\n",
    "\n",
    "    print('Start -> ', end=' ')\n",
    "    accuracy_scores[0] = cross_validate(Mahalanobis(), remaining_chans, protocol)\n",
    "    print(64, end=' ')\n",
    "\n",
    "    for it in range(62):\n",
    "        acc_tmp = [0]*len(remaining_chans)\n",
    "        for e, chan in enumerate(remaining_chans):\n",
    "            chan_set = remaining_chans.copy()\n",
    "            chan_set.remove(chan)\n",
    "            acc_tmp[e] = cross_validate(Mahalanobis(), chan_set, protocol)\n",
    "        max_idx = np.argmax(acc_tmp)\n",
    "        ranked_chans[protocol][it] = remaining_chans[max_idx]\n",
    "        accuracy_scores[it+1] = acc_tmp[max_idx]\n",
    "        remaining_chans.pop(max_idx)\n",
    "        print(63-it, end=' ')\n",
    "\n",
    "    acc_tmp = [0]*2\n",
    "    for e, chan in enumerate(remaining_chans):\n",
    "        chan_set = remaining_chans.copy()\n",
    "        chan_set.remove(chan)\n",
    "        acc_tmp[e] = cross_validate(NearestCentroid('euclidean'), chan_set, protocol) # mahalanobis doesn't work for datasets with 1 feature\n",
    "    max_idx = np.argmax(acc_tmp)\n",
    "    ranked_chans[protocol][-2] = remaining_chans[max_idx]\n",
    "    accuracy_scores[-1] = acc_tmp[max_idx]\n",
    "    remaining_chans.pop(max_idx)\n",
    "    print(1)\n",
    "    ranked_chans[protocol][-1] = remaining_chans[0]\n",
    "    print('\\n\\nDone!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadb54dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fig. 7a\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot(ranked_chans['EO'][1], 'r')\n",
    "plt.xticks(ticks=np.arange(4, 55, 10), labels=np.arange(60, 9, -10), fontsize=14)\n",
    "plt.gca().invert_xaxis()\n",
    "plt.ylim([10, 105])\n",
    "plt.yticks(fontsize=14)\n",
    "plt.plot(ranked_chans['EC'][1], 'b')\n",
    "plt.xlabel('Remaining Channels', fontsize=18), plt.ylabel('Accuracy (%)', fontsize=18)\n",
    "plt.legend(['Eyes Open', 'Eyes Close'], loc='lower right', fontsize=16)\n",
    "plt.scatter(44, (ranked_chans['EO'][1][44]+ranked_chans['EC'][1][44])/2, 300, c='k', marker='|')\n",
    "plt.plot([44, 44], [ranked_chans['EC'][1][44], 0], '--k')\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "# plt.savefig('RFE.png', dpi=200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50181d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('EO:', np.argmax(np.flip(ranked_chans['EO'][1]))+1, 'channels', np.max(ranked_chans['EO'][1]).round(1), '% accuracy')\n",
    "print('EC:', np.argmax(np.flip(ranked_chans['EC'][1]))+1, 'channels', np.max(ranked_chans['EC'][1]).round(1), '% accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a23f530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fig. 7b\n",
    "\n",
    "# topography visualized in matlab\n",
    "channel_ranks = {'EO': np.argsort(ranked_chans['EO'][0]), 'EC': np.argsort(ranked_chans['EC'][0])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0704415a",
   "metadata": {},
   "outputs": [],
   "source": [
    "savemat('channel_ranks.mat', channel_ranks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1faa960e",
   "metadata": {},
   "source": [
    "# Covariance Matrix Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80488ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table III\n",
    "\n",
    "seed(0)\n",
    "groupI_size = 20\n",
    "yI_train = np.array([i for i in range(groupI_size) for j in range(5)])\n",
    "yI_test = np.array([i for i in range(groupI_size)])\n",
    "accI = {'EO': {'self': [], 'other': [], 'no': []},\n",
    "        'EC': {'self': [], 'other': [], 'no': []}}\n",
    "yII_train = np.array([i for i in range(109-groupI_size) for j in range(5)])\n",
    "yII_test = np.array([i for i in range(109-groupI_size)])\n",
    "accII = {'EO': {'self': [], 'other': [], 'no': []},\n",
    "         'EC': {'self': [], 'other': [], 'no': []}}\n",
    "for protocol in ['EO', 'EC']:\n",
    "    for _ in range(500):\n",
    "        subjects = np.arange(109)\n",
    "        shuffle(subjects)\n",
    "        \n",
    "        groupI = subjects[:groupI_size]\n",
    "        accI_tmp = {'self': [0]*6, 'other': [0]*6, 'no': [0]*6}\n",
    "        \n",
    "        groupII = subjects[groupI_size:]\n",
    "        accII_tmp = {'self': [0]*6, 'other': [0]*6, 'no': [0]*6}\n",
    "        for i in range(6):\n",
    "\n",
    "            train_set = list(range(6))\n",
    "            test_set = [train_set.pop(i)]\n",
    "            invcovI = np.linalg.inv(np.cov(mcl[protocol][groupI][:, train_set, :, :].reshape(-1, 64).transpose()))\n",
    "            invcovII = np.linalg.inv(np.cov(mcl[protocol][groupII][:, train_set, :, :].reshape(-1, 64).transpose()))\n",
    "            \n",
    "            # group I\n",
    "            xI_train = mcl[protocol][groupI][:, train_set, :, :].reshape(-1, 64)\n",
    "            xI_test = mcl[protocol][groupI][:, test_set, :, :].reshape(-1, 64)\n",
    "            # covariance matrix: self\n",
    "            model = Mahalanobis(VI=invcovI)\n",
    "            model.fit(xI_train, yI_train)\n",
    "            accI_tmp['self'][i] = accuracy_score(yI_test, model.predict(xI_test))*100\n",
    "            # covariance matrix: other\n",
    "            model = Mahalanobis(VI=invcovII)\n",
    "            model.fit(xI_train, yI_train)\n",
    "            accI_tmp['other'][i] = accuracy_score(yI_test, model.predict(xI_test))*100\n",
    "            # covariance matrix: none\n",
    "            model = Euclidean()\n",
    "            model.fit(xI_train, yI_train)\n",
    "            accI_tmp['no'][i] = accuracy_score(yI_test, model.predict(xI_test))*100\n",
    "            \n",
    "            # group II\n",
    "            xII_train = mcl[protocol][groupII][:, train_set, :, :].reshape(-1, 64)\n",
    "            xII_test = mcl[protocol][groupII][:, test_set, :, :].reshape(-1, 64)\n",
    "            # covariance matrix: self\n",
    "            model = Mahalanobis(VI=invcovII)\n",
    "            model.fit(xII_train, yII_train)\n",
    "            accII_tmp['self'][i] = accuracy_score(yII_test, model.predict(xII_test))*100\n",
    "            # covariance matrix: other\n",
    "            model = Mahalanobis(VI=invcovI)\n",
    "            model.fit(xII_train, yII_train)\n",
    "            accII_tmp['other'][i] = accuracy_score(yII_test, model.predict(xII_test))*100\n",
    "            # covariance matrix: none\n",
    "            model = Euclidean()\n",
    "            model.fit(xII_train, yII_train)\n",
    "            accII_tmp['no'][i] = accuracy_score(yII_test, model.predict(xII_test))*100\n",
    "        \n",
    "        for covmat in ['self', 'other', 'no']:\n",
    "            accI[protocol][covmat].append([np.mean(accI_tmp[covmat]), np.std(accI_tmp[covmat])])\n",
    "            accII[protocol][covmat].append([np.mean(accII_tmp[covmat]), np.std(accII_tmp[covmat])])\n",
    "\n",
    "print('Group I')\n",
    "for covmat in ['self', 'other', 'no']:\n",
    "    mean_std = (np.mean(accI['EO'][covmat], 0).round(1), np.mean(accI['EC'][covmat], 0).round(1))\n",
    "    print('Performance using', covmat, 'covariance matrix:\\n',\n",
    "          'EO: {} \\N{PLUS-MINUS SIGN} {} %\\t'.format(mean_std[0][0], mean_std[0][1]),\n",
    "          'EC: {} \\N{PLUS-MINUS SIGN} {} %\\t'.format(mean_std[1][0], mean_std[1][1]))\n",
    "\n",
    "print('\\n\\nGroup II')\n",
    "for covmat in ['self', 'other', 'no']:\n",
    "    mean_std = (np.mean(accII['EO'][covmat], 0).round(1), np.mean(accII['EC'][covmat], 0).round(1))\n",
    "    print('Performance using', covmat, 'covariance matrix:\\n',\n",
    "          'EO: {} \\N{PLUS-MINUS SIGN} {} %\\t'.format(mean_std[0][0], mean_std[0][1]),\n",
    "          'EC: {} \\N{PLUS-MINUS SIGN} {} %\\t'.format(mean_std[1][0], mean_std[1][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af35f23",
   "metadata": {},
   "source": [
    "# Identification by Other Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7019b58f",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca63f4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.random import set_seed\n",
    "from numpy.random import seed\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bb7c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(0)\n",
    "set_seed(0)\n",
    "features = {'MCL': mcl, 'KFD': kfd, 'HM': hm, 'PSD': psd, 'AP': ap, 'PLV': plv, 'COH': coh, 'AR': ar}\n",
    "protocols = ['EO', 'EC']\n",
    "accuracy_scores = {'MCL': {'EO': None, 'EC': None}, 'KFD': {'EO': None, 'EC': None},\n",
    "                   'HM':  {'EO': None, 'EC': None}, 'PSD': {'EO': None, 'EC': None},\n",
    "                   'AP':  {'EO': None, 'EC': None}, 'PLV': {'EO': None, 'EC': None},\n",
    "                   'COH': {'EO': None, 'EC': None}, 'AR':  {'EO': None, 'EC': None}}\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "y_train = enc.fit_transform([[i] for i in range(109) for j in range(5)])\n",
    "y_test = enc.transform([[i] for i in range(109)])\n",
    "\n",
    "for feature in features.keys():\n",
    "    for protocol in protocols:\n",
    "        accuracy_scores_ = [0]*6\n",
    "        probability_scores_ = []\n",
    "        for i in range(6):\n",
    "            \n",
    "            train_set = list(range(6))\n",
    "            test_set = [train_set.pop(i)]\n",
    "            \n",
    "            x_train = features[feature][protocol][:, train_set, :, :].reshape(109*5, -1)\n",
    "            x_test = features[feature][protocol][:, test_set, :, :].reshape(109*1, -1)\n",
    "            \n",
    "            model = keras.Sequential([\n",
    "                    layers.BatchNormalization(input_shape=[x_train.shape[1]]),\n",
    "                    layers.Dense(100, activation='sigmoid'),\n",
    "                    layers.BatchNormalization(),\n",
    "                    layers.Dense(109, activation='softmax')\n",
    "                    ])\n",
    "            model.compile(\n",
    "                    optimizer='adam',\n",
    "                    loss='categorical_crossentropy',\n",
    "                    metrics='accuracy')\n",
    "            model.fit(\n",
    "                    x_train,\n",
    "                    y_train,\n",
    "                    batch_size=100,\n",
    "                    epochs=100,\n",
    "                    verbose=False)\n",
    "            \n",
    "            accuracy_scores_[i] = model.evaluate(x_test, y_test, verbose=False)[1]*100\n",
    "        \n",
    "        accuracy_scores[feature][protocol] = accuracy_scores_\n",
    "        print(feature+'-'+protocol+':',\n",
    "              np.mean(accuracy_scores_).round(1), '\\N{PLUS-MINUS SIGN}', np.std(accuracy_scores_).round(1), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0dba8e",
   "metadata": {},
   "source": [
    "## Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7cbf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3492d633",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {'MCL': mcl, 'KFD': kfd, 'HM': hm, 'PSD': psd, 'AP': ap, 'PLV': plv, 'COH': coh, 'AR': ar}\n",
    "protocols = ['EO', 'EC']\n",
    "accuracy_scores = {'MCL': {'EO': None, 'EC': None}, 'KFD': {'EO': None, 'EC': None},\n",
    "                   'HM':  {'EO': None, 'EC': None}, 'PSD': {'EO': None, 'EC': None},\n",
    "                   'AP':  {'EO': None, 'EC': None}, 'PLV': {'EO': None, 'EC': None},\n",
    "                   'COH': {'EO': None, 'EC': None}, 'AR':  {'EO': None, 'EC': None}}\n",
    "y_train = np.array([i for i in range(109) for j in range(5)])\n",
    "y_test = np.array([i for i in range(109)])\n",
    "\n",
    "for feature in features.keys():\n",
    "    for protocol in protocols:\n",
    "        accuracy_scores_ = [0]*6\n",
    "        probability_scores_ = []\n",
    "        n_components_ = [0]*6\n",
    "        for i in range(6):\n",
    "            \n",
    "            train_set = list(range(6))\n",
    "            test_set = [train_set.pop(i)]\n",
    "            \n",
    "            x_train = features[feature][protocol][:, train_set, :, :].reshape(109*5, -1)\n",
    "            x_test = features[feature][protocol][:, test_set, :, :].reshape(109*1, -1)\n",
    "            \n",
    "            model = SVC(kernel='linear')\n",
    "            model.fit(x_train, y_train)\n",
    "            \n",
    "            accuracy_scores_[i] = accuracy_score(y_test, model.predict(x_test))*100\n",
    "        \n",
    "        accuracy_scores[feature][protocol] = accuracy_scores_\n",
    "        print(feature+'-'+protocol+':',\n",
    "              np.mean(accuracy_scores_).round(1), '\\N{PLUS-MINUS SIGN}', np.std(accuracy_scores_).round(1), '%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
